# Phase 4: AI Story Generation - Technical Plan

> **Phase**: 4 - AI ì†Œì„¤ ìƒì„± ê¸°ëŠ¥ (í•µì‹¬ ê¸°ëŠ¥)
> **Priority**: â­â­â­â­â­ (í¬íŠ¸í´ë¦¬ì˜¤ í‰ê°€ 40%)
> **Dependencies**: Phase 3 (Writer Management) ì™„ë£Œ, OpenAI API í‚¤

---

## ğŸ“ Architecture Overview

### System Components

```mermaid
graph TB
    subgraph Frontend
        UI[React UI]
        SSE[EventSource Client]
    end

    subgraph Backend
        Controller[StoryController]
        Service[StoryService]
        AIService[AIService]
        Moderation[ModerationService]
    end

    subgraph External
        OpenAI[OpenAI GPT-4]
        ModAPI[Moderation API]
    end

    subgraph Database
        PG[(PostgreSQL)]
        Writer[Writer Table]
        Story[Story Table]
    end

    UI -->|POST /stories/generate| Controller
    Controller -->|SSE Stream| SSE
    Controller --> Service
    Service --> AIService
    Service --> Moderation
    AIService -->|Streaming| OpenAI
    Moderation --> ModAPI
    Service --> PG
    Service --> Writer
    Service --> Story
```

### Data Flow

```mermaid
sequenceDiagram
    participant U as User
    participant F as Frontend
    participant C as StoryController
    participant S as StoryService
    participant AI as AIService
    participant M as ModerationService
    participant GPT as OpenAI GPT-4
    participant DB as Database

    U->>F: ì‘ê°€ ì„ íƒ + íƒœê·¸ ì„ íƒ
    F->>C: POST /stories/generate (SSE)
    C->>S: generateStory(dto, userId)

    S->>DB: Writer ì¡°íšŒ (systemPrompt)
    DB-->>S: Writer data

    S->>AI: buildPrompt(systemPrompt, tags)
    AI-->>S: Optimized prompt

    S->>AI: streamGeneration(prompt)
    AI->>GPT: Stream request

    loop Streaming Tokens
        GPT-->>AI: Token chunk
        AI-->>S: Token chunk
        S-->>C: SSE: {chunk: "..."}
        C-->>F: Server-Sent Event
        F-->>U: Display token
    end

    GPT-->>AI: Stream complete
    AI-->>S: Full content

    S->>M: checkContent(content)
    M-->>S: Safe/Unsafe

    alt Content is Safe
        S->>AI: generateTitle(content)
        AI-->>S: Title
        S->>DB: Save story
        DB-->>S: Story ID
        S-->>C: SSE: {done: true, storyId}
        C-->>F: Generation complete
        F-->>U: Navigate to story
    else Content is Unsafe
        S->>AI: Retry generation (max 3)
        Note over S: If still fails, return error
    end
```

---

## ğŸ—„ï¸ Database Schema

### Story Model (Prisma)

```prisma
model Story {
  id          String   @id @default(cuid())
  title       String
  content     String   @db.Text
  tags        String[]
  wordCount   Int
  readTime    Int      // ë¶„ ë‹¨ìœ„ (wordCount / 200)

  // ê´€ê³„
  writerId    String
  writer      Writer   @relation(fields: [writerId], references: [id], onDelete: Cascade)

  userId      String
  user        User     @relation(fields: [userId], references: [id])

  bookmarks   Bookmark[]

  // ë©”íƒ€ë°ì´í„°
  createdAt   DateTime @default(now())
  updatedAt   DateTime @updatedAt

  // ì¸ë±ìŠ¤
  @@index([userId, createdAt(sort: Desc)])
  @@index([writerId, createdAt(sort: Desc)])
  @@index([tags])
}

model Bookmark {
  id        String   @id @default(cuid())
  userId    String
  storyId   String
  createdAt DateTime @default(now())

  user      User     @relation(fields: [userId], references: [id], onDelete: Cascade)
  story     Story    @relation(fields: [storyId], references: [id], onDelete: Cascade)

  @@unique([userId, storyId])
  @@index([userId])
}
```

### Migration

```bash
# Create migration
pnpm prisma migrate dev --name add-story-and-bookmark-models

# Expected SQL
CREATE TABLE "Story" (
  "id" TEXT NOT NULL PRIMARY KEY,
  "title" TEXT NOT NULL,
  "content" TEXT NOT NULL,
  "tags" TEXT[],
  "wordCount" INTEGER NOT NULL,
  "readTime" INTEGER NOT NULL,
  "writerId" TEXT NOT NULL,
  "userId" TEXT NOT NULL,
  "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
  "updatedAt" TIMESTAMP(3) NOT NULL,
  FOREIGN KEY ("writerId") REFERENCES "Writer"("id") ON DELETE CASCADE,
  FOREIGN KEY ("userId") REFERENCES "User"("id")
);

CREATE INDEX "Story_userId_createdAt_idx" ON "Story"("userId", "createdAt" DESC);
CREATE INDEX "Story_writerId_createdAt_idx" ON "Story"("writerId", "createdAt" DESC);
CREATE INDEX "Story_tags_idx" ON "Story"("tags");
```

---

## ğŸ§  AI Service Architecture

### Service Layer Structure

```
/apps/server/src/ai/
â”œâ”€â”€ ai.module.ts
â”œâ”€â”€ ai.service.ts              # ë©”ì¸ AI ë¡œì§
â”œâ”€â”€ providers/
â”‚   â”œâ”€â”€ openai.provider.ts     # OpenAI GPT-4 (Primary)
â”‚   â”œâ”€â”€ claude.provider.ts     # Anthropic Claude (Fallback 1)
â”‚   â””â”€â”€ openrouter.provider.ts # OpenRouter (Fallback 2)
â”œâ”€â”€ prompt/
â”‚   â”œâ”€â”€ prompt.builder.ts      # Prompt êµ¬ì¡° ìƒì„±
â”‚   â”œâ”€â”€ templates.ts           # Few-shot examples
â”‚   â””â”€â”€ optimization.ts        # í† í° ìµœì í™”
â”œâ”€â”€ moderation/
â”‚   â”œâ”€â”€ moderation.service.ts  # OpenAI Moderation API
â”‚   â””â”€â”€ korean-filter.ts       # í•œêµ­ì–´ í‚¤ì›Œë“œ í•„í„°
â””â”€â”€ dto/
    â”œâ”€â”€ generate-story.dto.ts
    â””â”€â”€ story-response.dto.ts
```

### AIService Interface

```typescript
// apps/server/src/ai/ai.service.ts

import { Injectable, Logger } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import OpenAI from 'openai';

@Injectable()
export class AIService {
  private readonly logger = new Logger(AIService.name);
  private readonly openai: OpenAI;

  constructor(private readonly config: ConfigService) {
    this.openai = new OpenAI({
      apiKey: this.config.get<string>('OPENAI_API_KEY'),
    });
  }

  /**
   * GPT-4ë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì†Œì„¤ ìƒì„±
   * @param systemPrompt - Writerì˜ systemPrompt (100-2000ì)
   * @param tags - ì¥ë¥´/ë¶„ìœ„ê¸°/ê²°ë§ íƒœê·¸ (1-3ê°œ)
   * @returns AsyncGenerator<string> - í† í° ìŠ¤íŠ¸ë¦¼
   */
  async *generateStoryStream(systemPrompt: string, tags: string[]): AsyncGenerator<string> {
    const prompt = this.buildPrompt(systemPrompt, tags);

    try {
      const stream = await this.openai.chat.completions.create({
        model: 'gpt-4-turbo-preview',
        messages: [
          { role: 'system', content: prompt.system },
          { role: 'user', content: prompt.user },
        ],
        temperature: 0.9, // ì°½ì˜ì„± ìµœëŒ€
        max_tokens: 4000, // ì¶©ë¶„í•œ ì—¬ìœ 
        presence_penalty: 0.6, // ì£¼ì œ ë‹¤ì–‘ì„±
        frequency_penalty: 0.3, // ë°˜ë³µ ë°©ì§€
        top_p: 0.95, // Nucleus sampling
        stream: true,
      });

      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content;
        if (content) {
          yield content;
        }
      }
    } catch (error) {
      this.logger.error('OpenAI streaming error', error);
      throw error;
    }
  }

  /**
   * ì†Œì„¤ ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ ì œëª© ìƒì„± (ë‹¨ì¼ ìš”ì²­)
   * @param content - ìƒì„±ëœ ì†Œì„¤ ì „ë¬¸
   * @returns Promise<string> - 10ì ì´ë‚´ ì œëª©
   */
  async generateTitle(content: string): Promise<string> {
    const response = await this.openai.chat.completions.create({
      model: 'gpt-4-turbo-preview',
      messages: [
        {
          role: 'system',
          content:
            'ë‹¹ì‹ ì€ ë‹¨í¸ ì†Œì„¤ì˜ ì œëª©ì„ ì§“ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 10ì ì´ë‚´ì˜ ê°„ê²°í•˜ê³  ì¸ìƒì ì¸ ì œëª©ì„ ë§Œë“œì„¸ìš”.',
        },
        {
          role: 'user',
          content: `ë‹¤ìŒ ì†Œì„¤ì˜ ì œëª©ì„ 10ì ì´ë‚´ë¡œ ì§€ì–´ì£¼ì„¸ìš”:\n\n${content.slice(0, 1000)}`,
        },
      ],
      temperature: 0.8,
      max_tokens: 50,
    });

    return response.choices[0].message.content?.trim() || 'ì œëª© ì—†ìŒ';
  }

  /**
   * Prompt êµ¬ì¡° ìƒì„± (Few-shot + Tags)
   */
  private buildPrompt(systemPrompt: string, tags: string[]): { system: string; user: string } {
    // Few-shot examples (ì¥ë¥´ë³„)
    const examples = this.getFewShotExamples(tags);

    const system = `
ë‹¹ì‹ ì€ ë›°ì–´ë‚œ í•œêµ­ì–´ ë‹¨í¸ ì†Œì„¤ ì‘ê°€ì…ë‹ˆë‹¤.

# ì‘ê°€ ìŠ¤íƒ€ì¼
${systemPrompt}

# ì‘ê°€ ìŠ¤íƒ€ì¼ í•™ìŠµ ì˜ˆì‹œ

${examples
  .map(
    (ex) => `
## ${ex.tags.join(', ')}
${ex.story}
`,
  )
  .join('\n\n')}

# ì´ì œ ë‹¹ì‹ ì˜ ì°¨ë¡€ì…ë‹ˆë‹¤.
ìœ„ ì˜ˆì‹œë“¤ê³¼ ê°™ì€ ìˆ˜ì¤€ì˜ í•œêµ­ì–´ ë‹¨í¸ ì†Œì„¤ì„ ì‘ì„±í•˜ì„¸ìš”.

ì¤‘ìš”: ì´ ì†Œì„¤ì€ ì •í™•íˆ 1,500ë‹¨ì–´ ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.
1,500ë‹¨ì–´ ë¯¸ë§Œìœ¼ë¡œ ëë‚´ì§€ ë§ˆì„¸ìš”. ë°˜ë“œì‹œ ì™„ì „í•œ ì´ì•¼ê¸°ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
`;

    const user = `
ë‹¤ìŒ ìŠ¤íƒ€ì¼ë¡œ ë‹¨í¸ ì†Œì„¤ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:
- ì¥ë¥´/ë¶„ìœ„ê¸°: ${tags.join(', ')}
- ê¸¸ì´: 1,500-2,000ë‹¨ì–´
- êµ¬ì¡°: ì‹œì‘-ì¤‘ê°„-ëì´ ì™„ì „í•œ ì´ì•¼ê¸°

ì§€ê¸ˆë¶€í„° 1,500ë‹¨ì–´ ì´ìƒì˜ ì†Œì„¤ì„ ì‘ì„±í•˜ì„¸ìš”.
`;

    return { system, user };
  }

  /**
   * íƒœê·¸ ê¸°ë°˜ Few-shot ì˜ˆì‹œ ì„ íƒ
   */
  private getFewShotExamples(tags: string[]): Array<{ tags: string[]; story: string }> {
    // templates.tsì—ì„œ íƒœê·¸ì™€ ìœ ì‚¬í•œ ì˜ˆì‹œ 2ê°œ ì„ íƒ
    // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë²¡í„° ìœ ì‚¬ë„ ë˜ëŠ” íƒœê·¸ ë§¤ì¹­ ì‚¬ìš©
    return [];
  }
}
```

---

## ğŸ­ Prompt Engineering Strategy

### Prompt Structure

```typescript
// apps/server/src/ai/prompt/prompt.builder.ts

export interface PromptComponents {
  writerStyle: string; // Writerì˜ systemPrompt
  fewShotExamples: string; // ì¥ë¥´ë³„ ì˜ˆì‹œ ì†Œì„¤
  constraints: string; // ê¸¸ì´, êµ¬ì¡° ì œì•½
  userRequest: string; // íƒœê·¸ ê¸°ë°˜ ìš”ì²­
}

export class PromptBuilder {
  /**
   * ìµœì¢… System Message êµ¬ì„±
   */
  buildSystemMessage(components: PromptComponents): string {
    return `
ë‹¹ì‹ ì€ ë›°ì–´ë‚œ í•œêµ­ì–´ ë‹¨í¸ ì†Œì„¤ ì‘ê°€ì…ë‹ˆë‹¤.

# ì‘ê°€ ì •ì²´ì„±
${components.writerStyle}

# í•™ìŠµ ì˜ˆì‹œ
${components.fewShotExamples}

# ì‘ì„± ê·œì¹™
${components.constraints}

# ì¤‘ìš” ì§€ì¹¨
- ì •í™•íˆ 1,500ë‹¨ì–´ ì´ìƒ ì‘ì„±
- ì‹œì‘-ì¤‘ê°„-ë ì™„ì „í•œ êµ¬ì¡°
- í•œêµ­ì–´ ìì—°ìŠ¤ëŸ¬ì›€ ìµœìš°ì„ 
- ìºë¦­í„°ì™€ í”Œë¡¯ ëª…í™•ì„±
`;
  }

  /**
   * User Message êµ¬ì„±
   */
  buildUserMessage(tags: string[]): string {
    return `
ë‹¤ìŒ ìŠ¤íƒ€ì¼ë¡œ ë‹¨í¸ ì†Œì„¤ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:
- ì¥ë¥´/ë¶„ìœ„ê¸°: ${tags.join(', ')}
- ê¸¸ì´: 1,500-2,000ë‹¨ì–´
- êµ¬ì¡°: ì™„ì „í•œ ì´ì•¼ê¸°

ì§€ê¸ˆë¶€í„° 1,500ë‹¨ì–´ ì´ìƒì˜ ì†Œì„¤ì„ ì‘ì„±í•˜ì„¸ìš”.
`;
  }
}
```

### Few-Shot Examples Database

```typescript
// apps/server/src/ai/prompt/templates.ts

export const FEW_SHOT_EXAMPLES = [
  {
    tags: ['í•˜ë“œë³´ì¼ë“œ', 'ëŠì™€ë¥´', 'ë°˜ì „'],
    wordCount: 1800,
    story: `ë¹„ëŠ” ë„ì‹œë¥¼ ì ì‹œê³ , ë‚´ ì‚¬ë¬´ì‹¤ ì°½ë¬¸ì„ ë‘ë“œë ¸ë‹¤.
ìˆ˜í™”ê¸° ë„ˆë¨¸ ì—¬ìì˜ ëª©ì†Œë¦¬ëŠ” ë–¨ë¦¬ê³  ìˆì—ˆë‹¤. "ê·¸ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”. ì œë°œ."
ë‚˜ëŠ” ë‹´ë°°ì— ë¶ˆì„ ë¶™ì´ë©° ëŒ€ë‹µí–ˆë‹¤. "ì£¼ì†Œë¥¼ ëŒ€ì‹œì˜¤."

[... 1,800 ë‹¨ì–´ ì™„ì„± ì†Œì„¤ ...]

ê·¸ê°€ ì‚´ì•„ìˆì—ˆë‹¤. í•˜ì§€ë§Œ ì°¾ë˜ ì‚¬ëŒì€ ë‚´ê°€ ì•„ë‹ˆì—ˆë‹¤.
ê·¸ë…€ê°€ ì°¾ë˜ ê±´, ì£½ì€ ë‚¨ìê°€ ì•„ë‹ˆë¼ ì‚´ì•„ìˆëŠ” ê±°ì§“ë§ì´ì—ˆë‹¤.`,
  },
  {
    tags: ['ë¡œë§¨ìŠ¤', 'ê²½ì¾Œí•œ', 'í•´í”¼ì—”ë”©'],
    wordCount: 1600,
    story: `ê·¸ê°€ ì¹´í˜ ë¬¸ì„ ì—´ê³  ë“¤ì–´ì˜¨ ìˆœê°„, ì‹œê°„ì´ ë©ˆì·„ë‹¤.
[... 1,600 ë‹¨ì–´ ...]
ìš°ë¦¬ëŠ” ì›ƒìœ¼ë©° ì„œë¡œì˜ ì†ì„ ì¡ì•˜ë‹¤. ì´ê²ƒì´ ì‹œì‘ì´ì—ˆë‹¤.`,
  },
  // ì¥ë¥´ë³„ ìµœì†Œ 3-5ê°œ ì˜ˆì‹œ í•„ìš”
];
```

### Token Optimization

```typescript
// apps/server/src/ai/prompt/optimization.ts

export class TokenOptimizer {
  /**
   * í”„ë¡¬í”„íŠ¸ í† í° ìˆ˜ ê³„ì‚° (tiktoken ì‚¬ìš©)
   */
  countTokens(text: string): number {
    // tiktoken ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ì •í™•í•œ í† í° ê³„ì‚°
    return Math.ceil(text.length / 4); // ê°„ë‹¨í•œ ì¶”ì •
  }

  /**
   * ìµœëŒ€ í† í° ì œí•œ ë‚´ì—ì„œ Few-shot ì˜ˆì‹œ ì„ íƒ
   * @param maxTokens - ì‹œìŠ¤í…œ ë©”ì‹œì§€ ìµœëŒ€ í† í° (ê¶Œì¥: 2000)
   */
  selectExamples(
    allExamples: typeof FEW_SHOT_EXAMPLES,
    tags: string[],
    maxTokens: number,
  ): typeof FEW_SHOT_EXAMPLES {
    // íƒœê·¸ ìœ ì‚¬ë„ ê¸°ë°˜ ì •ë ¬
    const sorted = allExamples.sort((a, b) => {
      const scoreA = this.calculateSimilarity(a.tags, tags);
      const scoreB = this.calculateSimilarity(b.tags, tags);
      return scoreB - scoreA;
    });

    // í† í° ì œí•œ ë‚´ì—ì„œ ìµœëŒ€í•œ í¬í•¨
    const selected = [];
    let totalTokens = 0;

    for (const example of sorted) {
      const tokens = this.countTokens(example.story);
      if (totalTokens + tokens < maxTokens) {
        selected.push(example);
        totalTokens += tokens;
      }
      if (selected.length >= 3) break; // ìµœëŒ€ 3ê°œ
    }

    return selected;
  }

  private calculateSimilarity(tags1: string[], tags2: string[]): number {
    const intersection = tags1.filter((t) => tags2.includes(t)).length;
    return intersection / Math.max(tags1.length, tags2.length);
  }
}
```

---

## ğŸ›¡ï¸ Safety & Moderation

### ModerationService

```typescript
// apps/server/src/ai/moderation/moderation.service.ts

import { Injectable, Logger } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import OpenAI from 'openai';
import { KoreanFilter } from './korean-filter';

@Injectable()
export class ModerationService {
  private readonly logger = new Logger(ModerationService.name);
  private readonly openai: OpenAI;
  private readonly koreanFilter: KoreanFilter;

  constructor(private readonly config: ConfigService) {
    this.openai = new OpenAI({
      apiKey: this.config.get<string>('OPENAI_API_KEY'),
    });
    this.koreanFilter = new KoreanFilter();
  }

  /**
   * 2ë‹¨ê³„ ì½˜í…ì¸  ê²€ì¦
   * 1. í•œêµ­ì–´ í‚¤ì›Œë“œ í•„í„° (ë¹ ë¦„)
   * 2. OpenAI Moderation API (ì •í™•í•¨)
   */
  async checkContent(content: string): Promise<{ safe: boolean; reason?: string }> {
    // Step 1: í•œêµ­ì–´ í‚¤ì›Œë“œ í•„í„° (ë¡œì»¬, ë¹ ë¦„)
    const koreanCheck = this.koreanFilter.check(content);
    if (!koreanCheck.safe) {
      this.logger.warn('Korean filter blocked content', { reason: koreanCheck.reason });
      return koreanCheck;
    }

    // Step 2: OpenAI Moderation API
    try {
      const response = await this.openai.moderations.create({
        input: content,
      });

      const result = response.results[0];

      if (result.flagged) {
        const categories = Object.entries(result.categories)
          .filter(([_, flagged]) => flagged)
          .map(([category]) => category);

        this.logger.warn('OpenAI moderation flagged content', { categories });

        return {
          safe: false,
          reason: `ë¶€ì ì ˆí•œ ì½˜í…ì¸  ê°ì§€: ${categories.join(', ')}`,
        };
      }

      return { safe: true };
    } catch (error) {
      this.logger.error('Moderation API error', error);
      // Moderation ì‹¤íŒ¨ ì‹œì—ë„ í†µê³¼ (ì„œë¹„ìŠ¤ ì¤‘ë‹¨ ë°©ì§€)
      return { safe: true };
    }
  }
}
```

### Korean Filter

```typescript
// apps/server/src/ai/moderation/korean-filter.ts

export class KoreanFilter {
  private readonly blockedKeywords = [
    // ìš•ì„¤
    'ì”¨ë°œ',
    'ê°œìƒˆë¼',
    'ë³‘ì‹ ',
    // ì„±ì  ì½˜í…ì¸ 
    'ì„¹ìŠ¤',
    'ì•¼ë™',
    // í­ë ¥
    'ì‚´ì¸',
    'ìì‚´',
    // í˜ì˜¤ í‘œí˜„
    'ê¹€ì¹˜ë…€',
    'í•œë‚¨',
  ];

  check(content: string): { safe: boolean; reason?: string } {
    const lowerContent = content.toLowerCase();

    for (const keyword of this.blockedKeywords) {
      if (lowerContent.includes(keyword)) {
        return {
          safe: false,
          reason: `ë¶€ì ì ˆí•œ í‚¤ì›Œë“œ ê°ì§€: ${keyword}`,
        };
      }
    }

    return { safe: true };
  }
}
```

---

## ğŸ”Œ API Endpoints

### StoryController

```typescript
// apps/server/src/story/story.controller.ts

import { Controller, Post, Get, Body, Query, Param, UseGuards, Sse } from '@nestjs/common';
import { JwtAuthGuard } from '../auth/guards/jwt-auth.guard';
import { CurrentUser } from '../auth/decorators/current-user.decorator';
import { StoryService } from './story.service';
import { GenerateStoryDto, StoryFiltersDto } from './dto';
import { Observable } from 'rxjs';

@Controller('stories')
@UseGuards(JwtAuthGuard)
export class StoryController {
  constructor(private readonly storyService: StoryService) {}

  /**
   * POST /stories/generate
   * SSE ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì†Œì„¤ ìƒì„±
   */
  @Sse('generate')
  generateStory(
    @Body() dto: GenerateStoryDto,
    @CurrentUser('id') userId: string,
  ): Observable<MessageEvent> {
    return this.storyService.generateStoryStream(dto, userId);
  }

  /**
   * GET /stories
   * ì‚¬ìš©ì ì†Œì„¤ ëª©ë¡ ì¡°íšŒ (pagination)
   */
  @Get()
  async getStories(@Query() filters: StoryFiltersDto, @CurrentUser('id') userId: string) {
    return this.storyService.getUserStories(userId, filters);
  }

  /**
   * GET /stories/:id
   * ì†Œì„¤ ìƒì„¸ ì¡°íšŒ
   */
  @Get(':id')
  async getStory(@Param('id') id: string, @CurrentUser('id') userId: string) {
    return this.storyService.getStory(id, userId);
  }

  /**
   * DELETE /stories/:id
   * ì†Œì„¤ ì‚­ì œ
   */
  @Delete(':id')
  async deleteStory(@Param('id') id: string, @CurrentUser('id') userId: string) {
    return this.storyService.deleteStory(id, userId);
  }
}
```

### DTOs

```typescript
// apps/server/src/story/dto/generate-story.dto.ts

import { IsString, IsNotEmpty, IsArray, ArrayMinSize, ArrayMaxSize } from 'class-validator';

export class GenerateStoryDto {
  @IsString()
  @IsNotEmpty({ message: 'writerIdëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.' })
  writerId: string;

  @IsArray({ message: 'tagsëŠ” ë°°ì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.' })
  @ArrayMinSize(1, { message: 'ìµœì†Œ 1ê°œì˜ íƒœê·¸ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.' })
  @ArrayMaxSize(3, { message: 'ìµœëŒ€ 3ê°œê¹Œì§€ íƒœê·¸ë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.' })
  @IsString({ each: true })
  tags: string[];
}

// apps/server/src/story/dto/story-filters.dto.ts

import { IsOptional, IsString, IsInt, Min, Max } from 'class-validator';
import { Type } from 'class-transformer';

export class StoryFiltersDto {
  @IsOptional()
  @Type(() => Number)
  @IsInt()
  @Min(1)
  page?: number = 1;

  @IsOptional()
  @Type(() => Number)
  @IsInt()
  @Min(1)
  @Max(50)
  limit?: number = 20;

  @IsOptional()
  @IsString()
  search?: string;

  @IsOptional()
  @IsString()
  tag?: string;

  @IsOptional()
  @IsString()
  writerId?: string;
}
```

---

## âš¡ Performance Optimization

### Response Time Targets

| Metric       | Target  | Strategy                            |
| ------------ | ------- | ----------------------------------- |
| ì²« í† í° ì‘ë‹µ | < 2ì´ˆ   | OpenAI API ìµœì í™”, í”„ë¡¬í”„íŠ¸ ê°„ì†Œí™”  |
| í† í°ë‹¹ ì§€ì—°  | < 100ms | ë„¤íŠ¸ì›Œí¬ ìµœì í™”, SSE ë²„í¼ë§         |
| ì „ì²´ ìƒì„±    | < 30ì´ˆ  | max_tokens ì œí•œ, temperature ìµœì í™” |
| ì œëª© ìƒì„±    | < 1ì´ˆ   | ì§§ì€ í”„ë¡¬í”„íŠ¸, ë‚®ì€ max_tokens      |
| DB ì €ì¥      | < 500ms | ì¸ë±ì‹±, íŠ¸ëœì­ì…˜ ìµœì í™”             |

### Caching Strategy

```typescript
// apps/server/src/ai/cache/prompt-cache.service.ts

import { Injectable } from '@nestjs/common';
import { Cache } from 'cache-manager';

@Injectable()
export class PromptCacheService {
  constructor(private readonly cacheManager: Cache) {}

  /**
   * Writer systemPrompt ìºì‹± (ìì£¼ ì‚¬ìš©ë˜ëŠ” ì‘ê°€)
   * TTL: 1ì‹œê°„
   */
  async getWriterPrompt(writerId: string): Promise<string | null> {
    return this.cacheManager.get(`writer-prompt:${writerId}`);
  }

  async setWriterPrompt(writerId: string, prompt: string): Promise<void> {
    await this.cacheManager.set(`writer-prompt:${writerId}`, prompt, 3600);
  }

  /**
   * Few-shot examples ìºì‹± (íƒœê·¸ ì¡°í•©ë³„)
   * TTL: 24ì‹œê°„
   */
  async getFewShotExamples(tags: string[]): Promise<any[] | null> {
    const key = `few-shot:${tags.sort().join(',')}`;
    return this.cacheManager.get(key);
  }
}
```

### Rate Limiting

```typescript
// apps/server/src/story/story.controller.ts

import { Throttle, ThrottlerGuard } from '@nestjs/throttler';

@Controller('stories')
@UseGuards(JwtAuthGuard, ThrottlerGuard)
export class StoryController {
  @Sse('generate')
  @Throttle(10, 86400) // ì¼ì¼ 10íšŒ ì œí•œ
  generateStory(...) { ... }
}
```

---

## ğŸ§ª Error Handling & Retry Logic

### Error Classification

```typescript
// apps/server/src/ai/errors/ai.errors.ts

export class AIServiceError extends Error {
  constructor(
    message: string,
    public readonly code: string,
    public readonly retryable: boolean,
  ) {
    super(message);
  }
}

export class OpenAITimeoutError extends AIServiceError {
  constructor() {
    super('OpenAI API timeout', 'OPENAI_TIMEOUT', true);
  }
}

export class OpenAIRateLimitError extends AIServiceError {
  constructor() {
    super('OpenAI rate limit exceeded', 'OPENAI_RATE_LIMIT', true);
  }
}

export class ModerationFailedError extends AIServiceError {
  constructor(reason: string) {
    super(`Content moderation failed: ${reason}`, 'MODERATION_FAILED', true);
  }
}

export class ContentUnsafeError extends AIServiceError {
  constructor(reason: string) {
    super(`Unsafe content detected: ${reason}`, 'CONTENT_UNSAFE', false);
  }
}
```

### Retry Strategy

```typescript
// apps/server/src/ai/utils/retry.util.ts

export interface RetryOptions {
  maxAttempts: number;
  delayMs: number;
  backoffFactor: number;
  retryableErrors: string[];
}

export async function retryWithBackoff<T>(fn: () => Promise<T>, options: RetryOptions): Promise<T> {
  let lastError: Error;
  let delay = options.delayMs;

  for (let attempt = 1; attempt <= options.maxAttempts; attempt++) {
    try {
      return await fn();
    } catch (error) {
      lastError = error;

      // ì¬ì‹œë„ ë¶ˆê°€ëŠ¥í•œ ì—ëŸ¬ë©´ ì¦‰ì‹œ throw
      if (error instanceof AIServiceError && !error.retryable) {
        throw error;
      }

      // ë§ˆì§€ë§‰ ì‹œë„ë©´ throw
      if (attempt === options.maxAttempts) {
        throw error;
      }

      // ì§€ìˆ˜ ë°±ì˜¤í”„
      await new Promise((resolve) => setTimeout(resolve, delay));
      delay *= options.backoffFactor;
    }
  }

  throw lastError!;
}
```

### StoryService with Retry

```typescript
// apps/server/src/story/story.service.ts

async generateStory(dto: GenerateStoryDto, userId: string): Promise<Story> {
  const writer = await this.prisma.writer.findUnique({
    where: { id: dto.writerId },
  });

  if (!writer) {
    throw new NotFoundException(`Writer ${dto.writerId} not found`);
  }

  // ì¬ì‹œë„ ë¡œì§: ìµœëŒ€ 3íšŒ
  const content = await retryWithBackoff(
    async () => {
      // 1. AI ìƒì„±
      const generated = await this.generateWithStreaming(writer.systemPrompt, dto.tags);

      // 2. Moderation ê²€ì¦
      const moderation = await this.moderationService.checkContent(generated);
      if (!moderation.safe) {
        throw new ModerationFailedError(moderation.reason!);
      }

      return generated;
    },
    {
      maxAttempts: 3,
      delayMs: 1000,
      backoffFactor: 2,
      retryableErrors: ['OPENAI_TIMEOUT', 'MODERATION_FAILED'],
    },
  );

  // 3. ì œëª© ìƒì„±
  const title = await this.aiService.generateTitle(content);

  // 4. DB ì €ì¥
  const wordCount = this.countWords(content);
  const readTime = Math.ceil(wordCount / 200);

  return this.prisma.story.create({
    data: {
      title,
      content,
      tags: dto.tags,
      wordCount,
      readTime,
      writerId: dto.writerId,
      userId,
    },
  });
}

private countWords(text: string): number {
  // í•œêµ­ì–´ëŠ” ê³µë°± ê¸°ì¤€, ì˜ì–´ëŠ” ë‹¨ì–´ ê¸°ì¤€
  return text.split(/\s+/).filter(w => w.length > 0).length;
}
```

---

## ğŸ¨ Frontend Implementation

### SSE Client (EventSource)

```typescript
// apps/web/src/api/stories.api.ts

export async function generateStory(
  dto: GenerateStoryDto,
  onChunk: (chunk: string) => void,
  onComplete: (storyId: string) => void,
  onError: (error: Error) => void,
): Promise<void> {
  const token = localStorage.getItem('access_token');
  const url = new URL(`${API_BASE_URL}/stories/generate`);

  // DTOë¥¼ query paramsë¡œ ì „ë‹¬ (SSEëŠ” POST body ë¶ˆê°€)
  url.searchParams.set('writerId', dto.writerId);
  url.searchParams.set('tags', JSON.stringify(dto.tags));

  const eventSource = new EventSource(url.toString(), {
    headers: {
      Authorization: `Bearer ${token}`,
    },
  });

  eventSource.onmessage = (event) => {
    const data = JSON.parse(event.data);

    if (data.chunk) {
      onChunk(data.chunk);
    } else if (data.done) {
      onComplete(data.storyId);
      eventSource.close();
    }
  };

  eventSource.onerror = (error) => {
    onError(new Error('Story generation failed'));
    eventSource.close();
  };
}
```

### React Component

```tsx
// apps/web/src/pages/stories/GenerateStoryPage.tsx

import { useState } from 'react';
import { useNavigate } from 'react-router-dom';
import { useWriters } from '@/api/writers.hooks';
import { generateStory } from '@/api/stories.api';

export function GenerateStoryPage() {
  const navigate = useNavigate();
  const { data: writers } = useWriters({ limit: 100 });

  const [selectedWriter, setSelectedWriter] = useState<string>('');
  const [selectedTags, setSelectedTags] = useState<string[]>([]);
  const [isGenerating, setIsGenerating] = useState(false);
  const [content, setContent] = useState('');
  const [progress, setProgress] = useState(0);

  const handleGenerate = async () => {
    if (!selectedWriter || selectedTags.length === 0) return;

    setIsGenerating(true);
    setContent('');
    setProgress(0);

    try {
      await generateStory(
        { writerId: selectedWriter, tags: selectedTags },
        // onChunk
        (chunk) => {
          setContent((prev) => prev + chunk);
          setProgress((prev) => Math.min(prev + 1, 95));
        },
        // onComplete
        (storyId) => {
          setProgress(100);
          setTimeout(() => {
            navigate(`/stories/${storyId}`);
          }, 1000);
        },
        // onError
        (error) => {
          alert('ì†Œì„¤ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: ' + error.message);
          setIsGenerating(false);
        },
      );
    } catch (error) {
      console.error(error);
      setIsGenerating(false);
    }
  };

  return (
    <div className="container mx-auto px-4 py-8">
      <h1 className="text-3xl font-bold mb-8">ìƒˆë¡œìš´ ì†Œì„¤ ìƒì„±</h1>

      {!isGenerating ? (
        <div className="max-w-2xl">
          {/* ì‘ê°€ ì„ íƒ */}
          <div className="mb-6">
            <label className="block mb-2 text-sm font-semibold">ì‘ê°€ ì„ íƒ</label>
            <select
              value={selectedWriter}
              onChange={(e) => setSelectedWriter(e.target.value)}
              className="w-full rounded-lg border border-border bg-background px-4 py-2"
            >
              <option value="">ì‘ê°€ë¥¼ ì„ íƒí•˜ì„¸ìš”</option>
              {writers?.data.map((writer) => (
                <option key={writer.id} value={writer.id}>
                  {writer.name}
                </option>
              ))}
            </select>
          </div>

          {/* íƒœê·¸ ì„ íƒ */}
          <div className="mb-6">
            <label className="block mb-2 text-sm font-semibold">ìŠ¤íƒ€ì¼ ì¡°í•© (ìµœëŒ€ 3ê°œ)</label>
            <div className="flex flex-wrap gap-2">
              {['ëŠì™€ë¥´', 'ìŠ¤ë¦´ëŸ¬', 'ë°˜ì „', 'ë¡œë§¨ìŠ¤', 'SF', 'íë§'].map((tag) => (
                <button
                  key={tag}
                  onClick={() => {
                    if (selectedTags.includes(tag)) {
                      setSelectedTags(selectedTags.filter((t) => t !== tag));
                    } else if (selectedTags.length < 3) {
                      setSelectedTags([...selectedTags, tag]);
                    }
                  }}
                  className={`rounded-full px-4 py-2 text-sm ${
                    selectedTags.includes(tag)
                      ? 'bg-primary text-primary-foreground'
                      : 'bg-muted text-muted-foreground'
                  }`}
                >
                  {tag}
                </button>
              ))}
            </div>
          </div>

          {/* ìƒì„± ë²„íŠ¼ */}
          <button
            onClick={handleGenerate}
            disabled={!selectedWriter || selectedTags.length === 0}
            className="w-full rounded-lg bg-primary px-6 py-3 text-primary-foreground disabled:opacity-50"
          >
            ì†Œì„¤ ìƒì„±í•˜ê¸°
          </button>
        </div>
      ) : (
        <div className="max-w-4xl">
          {/* ìƒì„± ì¤‘ í™”ë©´ */}
          <div className="mb-4">
            <div className="flex items-center justify-between mb-2">
              <span className="text-sm text-muted-foreground">ì†Œì„¤ ìƒì„± ì¤‘... {progress}%</span>
            </div>
            <div className="h-2 bg-muted rounded-full overflow-hidden">
              <div
                className="h-full bg-primary transition-all duration-300"
                style={{ width: `${progress}%` }}
              />
            </div>
          </div>

          {/* ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ */}
          <div className="rounded-lg border border-border bg-card p-6">
            <div className="whitespace-pre-wrap text-foreground">
              {content}
              <span className="inline-block w-2 h-5 bg-primary animate-pulse ml-1">â–Š</span>
            </div>
          </div>
        </div>
      )}
    </div>
  );
}
```

---

## ğŸ“Š Monitoring & Logging

### Metrics to Track

```typescript
// apps/server/src/story/metrics/story.metrics.ts

export interface StoryGenerationMetrics {
  storyId: string;
  userId: string;
  writerId: string;

  // ì„±ëŠ¥
  totalDuration: number; // ì „ì²´ ìƒì„± ì‹œê°„ (ms)
  firstTokenLatency: number; // ì²« í† í°ê¹Œì§€ (ms)
  tokensPerSecond: number; // í† í° ìƒì„± ì†ë„

  // í’ˆì§ˆ
  wordCount: number;
  retryCount: number;
  moderationPassed: boolean;

  // ë¹„ìš©
  promptTokens: number;
  completionTokens: number;
  totalCost: number; // USD

  // íƒ€ì„ìŠ¤íƒ¬í”„
  createdAt: Date;
}
```

### Logging Strategy

```typescript
// apps/server/src/story/story.service.ts

async generateStory(dto: GenerateStoryDto, userId: string): Promise<Story> {
  const startTime = Date.now();
  let firstTokenTime: number | null = null;
  let retryCount = 0;

  this.logger.log({
    event: 'story_generation_started',
    userId,
    writerId: dto.writerId,
    tags: dto.tags,
  });

  try {
    // ... ìƒì„± ë¡œì§ ...

    const duration = Date.now() - startTime;

    this.logger.log({
      event: 'story_generation_completed',
      userId,
      storyId: story.id,
      duration,
      wordCount: story.wordCount,
      retryCount,
      firstTokenLatency: firstTokenTime ? firstTokenTime - startTime : null,
    });

    // Metrics ì €ì¥ (PostHog, Sentry ë“±)
    await this.metricsService.record({
      event: 'story_generated',
      properties: {
        duration,
        wordCount: story.wordCount,
        retryCount,
      },
    });

    return story;
  } catch (error) {
    const duration = Date.now() - startTime;

    this.logger.error({
      event: 'story_generation_failed',
      userId,
      error: error.message,
      duration,
      retryCount,
    });

    // Sentry ë¦¬í¬íŠ¸
    Sentry.captureException(error, {
      tags: {
        operation: 'story_generation',
        userId,
        writerId: dto.writerId,
      },
    });

    throw error;
  }
}
```

---

## ğŸ§ª Testing Strategy

### Unit Tests

```typescript
// apps/server/src/ai/ai.service.spec.ts

describe('AIService', () => {
  let service: AIService;
  let openaiMock: jest.Mocked<OpenAI>;

  beforeEach(() => {
    openaiMock = createMock<OpenAI>();
    service = new AIService(mockConfigService);
    (service as any).openai = openaiMock;
  });

  describe('generateStoryStream', () => {
    it('should stream tokens from GPT-4', async () => {
      const mockStream = createMockStream([
        { choices: [{ delta: { content: 'ë¹„ëŠ”' } }] },
        { choices: [{ delta: { content: ' ë„ì‹œë¥¼' } }] },
      ]);

      openaiMock.chat.completions.create.mockResolvedValue(mockStream);

      const chunks: string[] = [];
      for await (const chunk of service.generateStoryStream('systemPrompt', ['ëŠì™€ë¥´'])) {
        chunks.push(chunk);
      }

      expect(chunks).toEqual(['ë¹„ëŠ”', ' ë„ì‹œë¥¼']);
    });

    it('should handle OpenAI API errors', async () => {
      openaiMock.chat.completions.create.mockRejectedValue(new Error('Rate limit exceeded'));

      await expect(async () => {
        for await (const _ of service.generateStoryStream('', [])) {
          // consume stream
        }
      }).rejects.toThrow('Rate limit exceeded');
    });
  });

  describe('generateTitle', () => {
    it('should generate title under 10 characters', async () => {
      openaiMock.chat.completions.create.mockResolvedValue({
        choices: [{ message: { content: 'ë¹„ ì˜¤ëŠ” ë°¤' } }],
      });

      const title = await service.generateTitle('ì†Œì„¤ ë‚´ìš©...');

      expect(title).toBe('ë¹„ ì˜¤ëŠ” ë°¤');
      expect(title.length).toBeLessThanOrEqual(10);
    });
  });
});
```

### Integration Tests

```typescript
// apps/server/test/story.e2e-spec.ts

describe('StoryController (e2e)', () => {
  let app: INestApplication;
  let accessToken: string;

  beforeAll(async () => {
    const moduleFixture = await Test.createTestingModule({
      imports: [AppModule],
    }).compile();

    app = moduleFixture.createNestApplication();
    await app.init();

    // ë¡œê·¸ì¸í•˜ì—¬ í† í° íšë“
    const loginRes = await request(app.getHttpServer())
      .post('/auth/login')
      .send({ email: 'test@test.com', password: 'test123' });

    accessToken = loginRes.body.access_token;
  });

  it('POST /stories/generate - should generate story with streaming', (done) => {
    const writerId = 'test-writer-id';
    const tags = ['ëŠì™€ë¥´', 'ìŠ¤ë¦´ëŸ¬'];

    const chunks: string[] = [];

    const eventSource = new EventSource(
      `http://localhost:3001/stories/generate?writerId=${writerId}&tags=${JSON.stringify(tags)}`,
      {
        headers: { Authorization: `Bearer ${accessToken}` },
      },
    );

    eventSource.onmessage = (event) => {
      const data = JSON.parse(event.data);

      if (data.chunk) {
        chunks.push(data.chunk);
      } else if (data.done) {
        expect(data.storyId).toBeDefined();
        expect(chunks.length).toBeGreaterThan(0);

        const fullContent = chunks.join('');
        const wordCount = fullContent.split(/\s+/).length;
        expect(wordCount).toBeGreaterThanOrEqual(1500);

        eventSource.close();
        done();
      }
    };

    eventSource.onerror = () => {
      fail('SSE connection failed');
      done();
    };
  }, 60000); // 60ì´ˆ íƒ€ì„ì•„ì›ƒ
});
```

### E2E Tests (Playwright)

```typescript
// apps/web/e2e/story-generation.spec.ts

import { test, expect } from '@playwright/test';

test.describe('Story Generation Flow', () => {
  test.beforeEach(async ({ page }) => {
    // ë¡œê·¸ì¸
    await page.goto('/login');
    await page.fill('[name="email"]', 'test@test.com');
    await page.fill('[name="password"]', 'test123');
    await page.click('button[type="submit"]');
    await expect(page).toHaveURL('/');
  });

  test('should generate story with streaming', async ({ page }) => {
    // ìƒì„± í˜ì´ì§€ ì´ë™
    await page.goto('/stories/new');

    // ì‘ê°€ ì„ íƒ
    await page.selectOption('select', { label: 'í•˜ë“œë³´ì¼ë“œ ì‘ê°€' });

    // íƒœê·¸ ì„ íƒ
    await page.click('text=ëŠì™€ë¥´');
    await page.click('text=ìŠ¤ë¦´ëŸ¬');
    await page.click('text=ë°˜ì „');

    // ìƒì„± ì‹œì‘
    await page.click('text=ì†Œì„¤ ìƒì„±í•˜ê¸°');

    // ìŠ¤íŠ¸ë¦¬ë° í™•ì¸ (ì²« í† í° 2ì´ˆ ì´ë‚´)
    await expect(page.locator('.whitespace-pre-wrap')).toContainText(/.+/, {
      timeout: 2000,
    });

    // ì™„ë£Œ ëŒ€ê¸° (30ì´ˆ ì´ë‚´)
    await expect(page).toHaveURL(/\/stories\/[a-z0-9]+/, { timeout: 30000 });

    // ì†Œì„¤ ë‚´ìš© í™•ì¸
    const content = await page.locator('.story-content').textContent();
    const wordCount = content!.split(/\s+/).length;
    expect(wordCount).toBeGreaterThanOrEqual(1500);
  });

  test('should show error on generation failure', async ({ page }) => {
    // ì˜ëª»ëœ ì‘ê°€ IDë¡œ ìƒì„± ì‹œë„ (ëª¨ì˜)
    await page.goto('/stories/new');

    // ... ì—ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
  });
});
```

---

## ğŸ” Environment Configuration

```bash
# apps/server/.env

# OpenAI
OPENAI_API_KEY=sk-...
OPENAI_ORG_ID=org-...

# Database
DATABASE_URL=postgresql://user:password@localhost:5432/snack_storyteller

# JWT
JWT_SECRET=your-secret-key
JWT_EXPIRES_IN=24h

# Rate Limiting
THROTTLE_TTL=86400
THROTTLE_LIMIT=10

# Monitoring
SENTRY_DSN=https://...
POSTHOG_API_KEY=phc_...

# File Upload
UPLOAD_DIR=./uploads
MAX_FILE_SIZE=5242880  # 5MB
```

---

## âœ… Success Criteria Checklist

### Functional Requirements

- [ ] **F1**: Writer ì„ íƒ ê°€ëŠ¥ (dropdown)
- [ ] **F1**: íƒœê·¸ ì„ íƒ ê°€ëŠ¥ (ì¥ë¥´, ë¶„ìœ„ê¸°, ê²°ë§ ì¤‘ ìµœëŒ€ 3ê°œ)
- [ ] **F1**: "ìƒì„±í•˜ê¸°" ë²„íŠ¼ í´ë¦­ ì‹œ ì†Œì„¤ ìƒì„± ì‹œì‘
- [ ] **F2**: GPT-4 í† í°ì´ ì‹¤ì‹œê°„ìœ¼ë¡œ í™”ë©´ì— í‘œì‹œ
- [ ] **F2**: íƒ€ìê¸° íš¨ê³¼ (typewriter animation)
- [ ] **F2**: ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ëŠê¹€ ì—†ìŒ
- [ ] **F3**: 1,500-2,000 ë‹¨ì–´ ë¶„ëŸ‰
- [ ] **F3**: Writerì˜ `systemPrompt` ìŠ¤íƒ€ì¼ ë°˜ì˜
- [ ] **F3**: í•œêµ­ì–´ ìì—°ìŠ¤ëŸ¬ì›€
- [ ] **F3**: ì‹œì‘-ì¤‘ê°„-ë ì™„ì „í•œ êµ¬ì¡°
- [ ] **F4**: AIê°€ ì†Œì„¤ ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ ì œëª© ìƒì„±
- [ ] **F4**: 10ì ì´ë‚´ ê°„ê²°í•œ ì œëª©
- [ ] **F5**: ìƒì„±ëœ ì†Œì„¤ ìë™ ì €ì¥
- [ ] **F5**: ë‹¨ì–´ ìˆ˜ (wordCount) ê³„ì‚°
- [ ] **F5**: ì˜ˆìƒ ì½ê¸° ì‹œê°„ (readTime) ê³„ì‚°
- [ ] **F5**: íƒœê·¸ ì •ë³´ ì €ì¥

### Non-Functional Requirements

- [ ] **N1**: ì²« í† í° ì‘ë‹µ ì‹œê°„ < 2ì´ˆ
- [ ] **N1**: ì „ì²´ ìƒì„± ì‹œê°„ < 30ì´ˆ
- [ ] **N1**: API ì‘ë‹µ ì‹œê°„ < 500ms (ë©”íƒ€ë°ì´í„° ì¡°íšŒ)
- [ ] **N2**: ìƒì„± ì„±ê³µë¥  > 95%
- [ ] **N2**: ì—ëŸ¬ ë°œìƒ ì‹œ ìë™ ì¬ì‹œë„ (ìµœëŒ€ 3íšŒ)
- [ ] **N2**: OpenAI API ì‹¤íŒ¨ ì‹œ Fallback (Claude)
- [ ] **N3**: OpenAI Moderation API í†µê³¼
- [ ] **N3**: í•œêµ­ì–´ ë¶€ì ì ˆí•œ í‚¤ì›Œë“œ í•„í„°ë§
- [ ] **N3**: 14ì„¸ ë¯¸ë§Œ ìœ í•´ ì½˜í…ì¸  ì°¨ë‹¨
- [ ] **N4**: ë™ì‹œ ìƒì„± ìš”ì²­ 100ê±´ ì²˜ë¦¬
- [ ] **N4**: Rate Limiting: ì‚¬ìš©ìë‹¹ ì¼ì¼ 10íšŒ
- [ ] **N5**: ì†Œì„¤ 1ê±´ë‹¹ ë¹„ìš© < $0.10
- [ ] **N5**: í† í° ìµœì í™” (ë¶ˆí•„ìš”í•œ í”„ë¡¬í”„íŠ¸ ì œê±°)
- [ ] **N5**: Caching ì „ëµ (Writer systemPrompt)

---

**ë‹¤ìŒ ë‹¨ê³„**: `tasks.md`ì—ì„œ êµ¬í˜„ ì‘ì—… ë¶„í•´
